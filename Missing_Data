# Handling Missing Data in R
# This script demonstrates strategies for identifying and handling missing data

# Load required libraries
library(readr)
library(dplyr)
library(tidyr)
library(forcats)
library(caret)
library(rpart)
library(recipes)

# Download and load the Titanic dataset
# Note: You may need to download the file manually if gdown is not available
# system("gdown 1tg9T97GfwstlY1R5AamcDkJuDFM01oL5")

# ========================================
# Understanding Missing Data
# ========================================

# In this lecture notes, we will deal with a dataset for a predictive task.
# If such a dataset has p+1 columns, we assume that p are the independent variables
# (also known as the features, or the inputs) and one column is the dependent variable
# (also known as the label or the output).
# Eventually, our task will be that of devising and training a machine learning model
# that predicts the label based on the features.

# Missing data are values at specific rows (i.e., observations) and columns
# (i.e., features) that are not available in the dataset.
# It is important to remark that, to train a prediction model, missing data can be
# in one of the feature columns but **not** in the label column.
# An observation without a valid label is not serviceable and must be discarded.

# When a piece of data seems to be missing from a dataset, i.e., there is an "empty"
# cell in a tabular dataset, we must first determine if the missingness of the data
# is a valid state or not.

# ========================================
# Types of Missing Data
# ========================================

# **Missing Completely at Random (MCAR)**:
# Values are missing completely at random if their missingness is unrelated to both
# observable and unobservable variables.
# For example, consider a temperature sensor that sometimes stops working, and it is
# not possible to associate this malfunction with any other environmental parameter
# (both inside and outside of our dataset).
# For MCAR data, the probability that a value is missing is independent of the data
# and is the same for all values.

# **Missing at Random (MAR)**:
# Values are missing at random if their missingness depends on some observed property
# of the data.
# For example, if the temperature sensor is more likely to stop working in highly
# humid environments, then data recorded where humidity is high has a higher chance
# of containing a missing value.
# If the humidity level is recorded, a preliminary data analysis might reveal the
# correlation between humidity and the probability that the temperature is missing.
# It's important to remark that, assuming that humidity is the only factor affecting
# the sensor's reliability, if we could separate our data by humidity, missing data
# *for a given humidity level* would be MCAR.

# **Missing Not at Random (MNAR)**:
# Values are missing not at random when the missingness of a value is related to the
# value that this variable would have if it were not missing.
# Imagine that the temperature sensor has a high chance of stop working at high
# temperatures. Then, high temperature values are more likely to be missing.
# But, precisely because these values are missing, we have no direct way to suspect
# that high temperatures are associated with a higher chance of missing values.

# ========================================
# Load and Explore the Titanic Dataset
# ========================================

# Read the data
d <- read_csv('titanic.csv')

# The data has the following features:
# * pclass: the class the passenger was travelling in (categorical: first, second, or third)
# * name: the passenger's name (a string)
# * sex: the passenger's sex (categorical: male or female)
# * age: the passenger's age (non-negative integer)
# * siblings_and_spouses_onboard: number of siblings and spouse(s) the passenger had onboard
# * parents_and_children_onboard: number of parents and children the passenger had onboard
# * ticket: passenger's ticket number, as it was sold by the navigation company
# * fare: fare paid by the passenger
# * cabin: number/code of the cabin where the passenger was staying
# * embarkment_port: port where the passenger embarked (categorical: Cherbourg, Queenstown, Southampton)
# * lifeboat: id code of the lifeboat the passenger got on, if any
# * body_id_number: id code of the passenger's body, if the passenger died and their body was retrieved
#
# And the following label:
# * survived: whether the passenger survived the shipwreck (categorical: Yes or No)

# Mark categorical data as such
d <- d %>%
  mutate(
    pclass = as_factor(pclass),
    sex = as_factor(sex),
    survived = as_factor(survived),
    embarkment_port = as_factor(embarkment_port)
  )

# View summary statistics
summary(d)

# ========================================
# Analyzing Missing Data Patterns
# ========================================

# Observations about body_id_number:
# * Column body_id_number has many missing values, but not all of these are invalid.
# * If a person survived, they will not have a body id number.
# * Even if they did not survive, their body might have never been recovered.
# * We should REMOVE this column for prediction because it contains information only
#   available after the shipwreck.

# Drop the body_id_number column
d <- d %>%
  select(!body_id_number)

# Observations about age:
# * Column age has missing values and these definitely do not correspond to valid states
# * We don't know if this data is missing completely at random, at random, or not at random
# * For example, it is plausible that onboard records of 3rd-class passengers were not
#   as thorough as the records of 1st-class passengers

# Helper function: Print the percentage of missing values in val_col for each group
# defined by grp_col
pct_missing <- function(data, grp_col, val_col) {
  data %>%
    group_by(across(all_of(grp_col))) %>%
    summarise(pct_missing = mean(is.na(across(all_of(val_col)))) * 100)
}

# Remarks about the above function:
# * We need to use across() because otherwise R expects to find a literal column name
# * If we did not use across(), and we just wrote group_by(grp_col), R would be looking
#   for a column called literally "grp_col", rather than looking for the column whose
#   name is contained in the grp_col string
# * When using across(), we further have to use all_of, because across expects
#   "tidyselect syntax" and not a raw string (see the documentation)

# Percentage of missing values in column "age" in each group defined by column "pclass"
d %>%
  pct_missing(grp_col = "pclass", val_col = "age")

# This theory might be plausible: third-class passengers have a much higher percentage
# of missing values.
# Still, perhaps surprisingly, it's second-class passengers who have the fewest missing
# values, and not first-class ones.
#
# Another hypothesis is that not many children got their age recorded.
# If third-class passengers included predominantly emigrant families with many children,
# this might explain the missingness.

# Average age per group defined by column "pclass"
d %>%
  group_by(pclass) %>%
  summarise(mean_age = mean(age, na.rm = TRUE))

# Indeed, the average (recorded) age among third-class passengers is the lowest.
# Still, second-class passengers have a lower average age than first-class passengers,
# but a smaller fraction of missing data.
#
# For the moment, it's hard to make further hypothesis about the missingness of the
# age feature.
# Remark that our first hypothesis would have implied that values are missing at random
# (assuming that pclass was the *only* contributing factor to age's missingness), while
# the second one would have implied that values are missing not at random.

# ========================================
# Analyzing cabin and lifeboat columns
# ========================================

# More observations:
# * The cabin and lifeboat columns have many missing values.
# * However, in many instances, these missing values can correspond to valid world-states.
# * For example, passengers in lower classes did not have cabins and were lodged in dormitories.
# * And, unfortunately, not everyone had space on the lifeboats.

# Percentage of missing values in column "cabin" in each group defined by column "pclass"
d %>%
  pct_missing(grp_col = "pclass", val_col = "cabin")

# Indeed, almost no second- or third-class passenger has an assigned cabin.
# Conversely, presumably all first-class passengers were assigned a cabin.
# Still, more than 20% of data about first-class passengers has no information on
# their cabin and this is likely to be "really" missing data.

# Percentage of missing values in column "lifeboat" in each group defined by column "survived"
d %>%
  pct_missing(grp_col = "survived", val_col = "lifeboat")

# As the above analysis shows, if we assume that having a missing value in column
# lifeboat means that the person did not make it into a lifeboat, then not making
# it is strongly correlated with not surviving.
#
# In other words, if we assume that all the missing values in the lifeboat column
# correspond to the real-life scenario of a person not getting into a lifeboat,
# 98.9% of people who did not embark on a lifeboat died (and 1.1% survived),
# whereas only 4.6% of those who embarked a lifeboat died (and 95.6% survived).

# ========================================
# Analyzing fare and embarkment_port columns
# ========================================

# More observations:
# * Columns fare and embarkment_port have very few missing values.
# * Is there something special about the observation with the missing values?

# Rows with NA in the "fare" column
d %>%
  filter(is.na(fare))

# A third-class passenger. Hard to believe that he was gifted a free ticket for being
# an influencer... this must be missing data!

# Rows with NA in the "embarkment_port" column
d %>%
  filter(is.na(embarkment_port))

# ========================================
# Dealing with Missing Data
# ========================================

# Now that we have established that some data is missing in our dataset, we can
# develop strategies to deal with it.
#
# Indeed, several machine learning algorithms cannot deal with missing data and
# require that there are no missing values in any of the feature columns (recall:
# in no case can there be missing values in the label column).
#
# The first strategy to fill in missing data is to try to recover the correct value
# from alternative data sources.
# For example, we can recover the embarkment port of Ms. Icard and Mrs. Stone from
# the Encyclopedia Titanica (https://www.encyclopedia-titanica.org/).

# After a quick search, the embarkment port for the two passengers with missing
# value is Southampton. Fill it in.
d <- d %>%
  mutate(embarkment_port = replace_na(embarkment_port, "Southampton"))

# ========================================
# Row or Column Removal
# ========================================

# Another way of dealing with missing data is to remove either columns or rows from
# the dataset.
#
# * We can remove entire columns if they have a large share of missing values and
#   very few valid values.
# * We can remove entire rows if they have multiple missing values (i.e., they are
#   low-quality observations) or even if they only have one missing value, but we
#   have so much data that we can afford to reduce the number of observations.
#
# Before evaluating if we should remove any column or row from our dataset, let us
# replace the values currently marked as missing but potentially corresponding to
# valid states.

# Replace NA in the "lifeboat" column with the string "None", assuming that
# passengers with a missing lifeboat identifier did not make it into any lifeboat.
d <- d %>%
  mutate(lifeboat = replace_na(lifeboat, "None"))

# We might have made some small error in the above process.
# For example, we assume that all people without a valid lifeboat entry did not get
# into a lifeboat.
# On the other hand, we cannot exclude the possibility that some missing values in
# the lifeboat column correspond to people who did get a spot on a lifeboat and this
# information is missing in our dataset.
# Still, some compromise is necessary when dealing with a real-life dataset, and this
# is a reasonable one.

# View current state of missing data
summary(d)

# The cabin column has a very high percentage of missing value.
# In this example, we remove it.

# Remove the "cabin" column
d <- d %>%
  select(!cabin)

# How many rows contain >1 missing values?
# To do so, we only keep rows whose row-wise sum of is.na is larger than one.
d %>%
  filter(rowSums(is.na(.)) > 1) %>%
  nrow()

# There is no observation with more than one missing value.
# Let us not remove any row, then, and move to the next strategy: replacing missing
# values through imputation.

# ========================================
# Imputation
# ========================================

# To impute a missing value means to replace it with some valid value.
# There are many strategies for imputing data.
#
# The most basic ones include replacing the missing value with a representative value
# from the dataset.
# For numeric columns, this is usually the mean or the median.
# For categorical columns, it is usually the mode.
# In the most basic version of this imputation technique, these statistics are computed
# over (the valid entries of) the entire dataset.
#
# A slightly more advanced technique computes the above statistics (mean, median or mode)
# on a subset of the data that shares some characteristics with the observation that we
# are imputing.
# For example, we can impute the fare column with the mean fare for passengers in the
# same class.
# Remark that we can use this method only for observations that do not have missing
# values in the fare and pclass columns simultaneously.
#
# Finally, there are more advanced techniques that treat imputation as a prediction task.
# These techniques include MICE (multivariate imputation via chained equations) and other
# methods based on k-nearest neighbours or regression models.
#
# In our class, we consider the more basic imputation techniques.

# Impute "age" and "fare" using the group-by-group average computed over the groups
# defined by "pclass"
d <- d %>%
  group_by(pclass) %>%
  mutate(
    age = replace_na(age, mean(age, na.rm = TRUE)),
    fare = replace_na(fare, mean(fare, na.rm = TRUE))
  ) %>%
  ungroup()

# No NA's left
summary(d)

# Our data no longer has missing values!

# ========================================
# CRITICAL: Cannot Impute Using the Label
# ========================================

# We reinforce a basic concept of imputation: the **label** cannot be used for
# imputation; not even indirectly.
#
# We have already stated that the label cannot be imputed, i.e., it cannot be used
# directly.
#
# Moreover, the label cannot be used indirectly.
# For example, we cannot impute different values depending on the label.
# The reason is that, in production, the new data that comes in only has the features
# but not the label (because, indeed, we must *predict* the label).
# Therefore, in production, it would be impossible to employ a technique that uses the
# label to impute feature values.

# ========================================
# CRITICAL: Do Not Cause Information Leakage!
# ========================================

# In the previous example, we have imputed the data directly into the dataframe.
# This means that we used potentially all observations to compute the statistics
# (mean in our case, median and mode in other cases) that were then used for imputation.
#
# As you will soon see, when a dataset is used for a predictive task, it is often
# first divided into training data and test data.
# The training data is used to train the machine learning models.
# For parametric models, training involves learning good values for their parameters:
# values that enable the model to make accurate predictions when presented with new data.
# During training, we select parameter values that yield a low prediction error, i.e.,
# those that enable the model to predict labels that are close to the ground-truth label.
#
# However, we are really interested in knowing how models will perform when deployed
# in production.
# We also want to appraise their future performance before actually deploying them in
# production.
# For example, if we must choose between two different models, we want to select the
# best one before it is deployed, not after.
# To this end, we do not use all our available data for training; instead, we split
# the data into two parts.
# The training data is used to train the models, while the test data is used as a
# "simulation" of future production data and is only used to evaluate the models.
# For this evaluation to be unbiased, the test data must be kept completely separate
# from the training data.
#
# Suppose we impute missing values in our dataset before this separation.
# In that case, some test points will be included in the calculation of the statistics
# (such as the mean) used in data imputation.
# Therefore, best practices involve using only training data for imputation and then
# applying the statistics computed on the training data to impute values in the test data.
# This approach avoids *information leakage*, i.e., that some information contained in
# the test data leaks, however indirectly, into the training data.
# In R, this is achieved by using recipes and including the imputation step in the recipe.

# ========================================
# Example: Imputation + Machine Learning (Correct Way)
# ========================================

# Load the data fresh for the machine learning example
d <- read_csv('titanic.csv')
d <- d %>%
  select(-c(name, ticket, body_id_number, cabin)) %>%  # Remove columns not used in prediction
  mutate(lifeboat = if_else(is.na(lifeboat), "No", "Yes")) %>%  # Replace missing with "No", non-missing with "Yes"
  mutate(
    pclass = as_factor(pclass),
    sex = as_factor(sex),
    embarkment_port = as_factor(embarkment_port),
    lifeboat = as_factor(lifeboat)
  )  # Mark categorical columns as such

# Split data into training and test sets (80/20 split)
train_index <- createDataPartition(d$survived, p = 0.8, list = FALSE)
train_data <- d[train_index, ]
test_data <- d[-train_index, ]

# Identify numerical and categorical features
numerical_features <- train_data %>%
  select(where(is.numeric)) %>%
  colnames()

categorical_features <- train_data %>%
  select(where(is.factor)) %>%
  colnames() %>%
  setdiff("survived")  # Exclude the label

# Recipes are the closest thing to sklearn's pipelines
# CRITICAL: This recipe is fitted ONLY on training data
titanic_recipe <- recipe(survived ~ ., data = train_data) %>%
  step_impute_mean(all_of(numerical_features)) %>%      # Impute numerical features with mean
  step_impute_mode(all_of(categorical_features)) %>%    # Impute categorical features with mode
  step_dummy(all_of(categorical_features))              # One-hot encode categorical features

# The "fitting" of the preprocessing steps on the training data must be done manually,
# using the prep() function.
# This is where the recipe LEARNS the statistics (means, modes) from the TRAINING data only
prepared_recipe <- prep(titanic_recipe, training = train_data)

# Once a recipe has been prep()-ped on the training data, it can be bake()-d on the
# test data.
# CRITICAL: The test data is transformed using statistics learned from training data
# With sklearn's pipelines this was done automatically.
train_processed <- bake(prepared_recipe, new_data = train_data)
test_processed <- bake(prepared_recipe, new_data = test_data)

# ========================================
# Model Training with Cross-Validation
# ========================================

# Homemade version of Python's GridSearchCV
# R's trees from package rpart do not have all the hyperparameters that Python's
# DecisionTreeClassifier has.
# We only use the "cp" pruning strength hyperparameter.

param_grid_cp <- c(0, 0.0001, 0.001, 0.01, 0.1)

best_cp <- 0
best_xerror <- Inf

for(cp_value in param_grid_cp) {
  tuned_model <- rpart(
    survived ~ .,
    data = train_processed,
    control = rpart.control(cp = cp_value),
    xval = 5  # 5-fold cross-validation
  )
  
  min_xerror_index <- which.min(tuned_model$cptable[, "xerror"])
  current_xerror <- tuned_model$cptable[min_xerror_index, "xerror"]
  
  if(current_xerror < best_xerror) {
    best_xerror <- current_xerror
    best_cp <- cp_value
  }
}

# Train final model with best hyperparameter
final_rpart_model <- rpart(
  survived ~ ., 
  data = train_processed, 
  control = rpart.control(cp = best_cp)
)

print(paste("Best hyperparameter value found (cp):", best_cp))

# ========================================
# Model Evaluation
# ========================================

# Make predictions on test set
predictions <- predict(final_rpart_model, newdata = test_processed, type = "class")

# Calculate accuracy
accuracy <- mean(predictions == test_processed$survived)
print(paste("Accuracy on the test set:", accuracy))

# ========================================
# Key Takeaways
# ========================================

# 1. Always split data BEFORE imputation
# 2. Compute imputation statistics from TRAINING data only
# 3. Apply those same statistics to BOTH training and test data
# 4. Never use the label for imputation (directly or indirectly)
# 5. Use recipes in R to prevent information leakage

# ========================================
# Further References
# ========================================

# * Applied missing data analysis. Enders, Craig. Guilford (2022).
# * The missing book. Tierney, Nicholas and Horst, Allison. (2022).
#   https://tmb.njtierney.com/
# * Flexible imputation of missing data. van Buuren, Stef. CRC Press (2018).
#   https://stefvanbuuren.name/fimd/
